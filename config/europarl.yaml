label: 'europarl'
description: "medium-sized character-level NMT model"

dropout_rate: 0.2

layers: 1
bidir: True
use_lstm: False
#initializer: uniform
#weight_scale: 0.01
weight_scale: 0.1

data_dir: experiments/europarl/data
model_dir: experiments/europarl/model
batch_size: 64

optimizer: 'adam'
learning_rate: 0.001

steps_per_checkpoint: 1000
steps_per_eval: 1000
score_function: corpus_scores

max_gradient_norm: 1.0
batch_mode: 'standard'
read_ahead: 20

#max_train_size: 500000  # read only this many data points at once
parallel_iterations: 8
swap_memory: True

encoders:
  - name: en
    ext: char.en
    max_len: 320  # 95% coverage of train set
    character_level: True
    maxout_stride: 5
    convolutions: [150, 150, 150, 200, 200, 200, 250, 250]
    embedding_size: 256
    cell_size: 512
    attn_size: 512

decoders:
  - name: fr
    ext: char.fr
    character_level: True
    max_len: 360  # 95% coverage of train set
    maxout: True
    embedding_size: 512
    cell_size: 1024
    layers: 2
    vanilla: True
    attn_prev_word: True

#mem_fraction: 0.8
#allow_growth: False
