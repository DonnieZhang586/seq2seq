05/08 18:22:12 label: default
05/08 18:22:12 description:
  default configuration
  next line of description
  last line
05/08 18:22:12 /home/eske/Documents/seq2seq/translate/__main__.py experiments/APE17/edits/noisy/forced-noisy.yaml --train -v --purge --raw-output
05/08 18:22:12 commit hash 54ece792eef4b526ec9d52ee724c70b4a6591f58
05/08 18:22:12 program arguments
05/08 18:22:12   align_edits          False
05/08 18:22:12   align_encoder_id     0
05/08 18:22:12   allow_growth         True
05/08 18:22:12   attention_type       'global'
05/08 18:22:12   attention_window_size 0
05/08 18:22:12   attn_size            256
05/08 18:22:12   batch_mode           'standard'
05/08 18:22:12   batch_norm           False
05/08 18:22:12   batch_size           32
05/08 18:22:12   beam_size            1
05/08 18:22:12   bidir                True
05/08 18:22:12   cell_size            256
05/08 18:22:12   character_level      False
05/08 18:22:12   config               'experiments/APE17/edits/noisy/forced-noisy.yaml'
05/08 18:22:12   data_dir             'experiments/APE17/edits/data'
05/08 18:22:12   decay_after_n_epoch  1
05/08 18:22:12   decay_every_n_epoch  0.5
05/08 18:22:12   decay_if_no_progress None
05/08 18:22:12   decoder              {'aggregation_method': None,
 'align_edits': False,
 'attention_type': 'global',
 'attention_window_size': 0,
 'attn_size': 256,
 'batch_norm': False,
 'bidir': True,
 'cell_size': 256,
 'chained_encoders': None,
 'character_level': False,
 'embedding_size': 256,
 'layer_norm': False,
 'layers': 1,
 'lstm_dropout': False,
 'name': 'edits',
 'parallel_iterations': 16,
 'pred_edits': True,
 'swap_memory': True,
 'use_context': None,
 'use_lstm': True,
 'vocab_size': 0}
05/08 18:22:12   description          'default configuration\nnext line of description\nlast line\n'
05/08 18:22:12   dev_prefix           ['train-dev']
05/08 18:22:12   dropout_rate         0.5
05/08 18:22:12   early_stopping       True
05/08 18:22:12   edit_window_size     None
05/08 18:22:12   embedding_size       256
05/08 18:22:12   encoders             [{'aggregation_method': None,
  'align_edits': True,
  'attention_type': 'local',
  'attention_window_size': 0,
  'attn_size': 256,
  'batch_norm': False,
  'bidir': True,
  'cell_size': 256,
  'chained_encoders': None,
  'character_level': False,
  'embedding_size': 256,
  'layer_norm': False,
  'layers': 1,
  'lstm_dropout': False,
  'name': 'mt',
  'parallel_iterations': 16,
  'pred_edits': False,
  'swap_memory': True,
  'use_context': None,
  'use_lstm': True,
  'vocab_size': 0}]
05/08 18:22:12   ensemble             False
05/08 18:22:12   eval_burn_in         0
05/08 18:22:12   feed_previous        0.0
05/08 18:22:12   freeze_variables     []
05/08 18:22:12   gpu_id               0
05/08 18:22:12   keep_best            4
05/08 18:22:12   keep_every_n_hours   0
05/08 18:22:12   label                'default'
05/08 18:22:12   layer_norm           False
05/08 18:22:12   layers               1
05/08 18:22:12   learning_rate        1.0
05/08 18:22:12   learning_rate_decay_factor 0.8
05/08 18:22:12   len_normalization    1.0
05/08 18:22:12   load                 []
05/08 18:22:12   log_file             'log.txt'
05/08 18:22:12   lstm_dropout         False
05/08 18:22:12   max_dev_size         0
05/08 18:22:12   max_epochs           80
05/08 18:22:12   max_gradient_norm    1.0
05/08 18:22:12   max_input_len        45
05/08 18:22:12   max_output_len       50
05/08 18:22:12   max_steps            0
05/08 18:22:12   max_to_keep          1
05/08 18:22:12   max_train_size       0
05/08 18:22:12   mem_fraction         1.0
05/08 18:22:12   model_dir            'experiments/APE17/edits/noisy/forced_noisy'
05/08 18:22:12   no_gpu               False
05/08 18:22:12   optimizer            'sgd'
05/08 18:22:12   output               None
05/08 18:22:12   parallel_iterations  16
05/08 18:22:12   pred_edits           False
05/08 18:22:12   purge                True
05/08 18:22:12   raw_output           True
05/08 18:22:12   read_ahead           10
05/08 18:22:12   remove_unk           False
05/08 18:22:12   score_function       'corpus_scores_ter'
05/08 18:22:12   script_dir           'scripts'
05/08 18:22:12   sgd_after_n_epoch    None
05/08 18:22:12   sgd_learning_rate    1.0
05/08 18:22:12   shuffle_data         True
05/08 18:22:12   steps_per_checkpoint 400
05/08 18:22:12   steps_per_eval       400
05/08 18:22:12   swap_memory          True
05/08 18:22:12   train                True
05/08 18:22:12   train_prefix         'train.noisy'
05/08 18:22:12   use_lstm             True
05/08 18:22:12   verbose              True
05/08 18:22:12   vocab_prefix         'vocab.noisy'
05/08 18:22:12   vocab_size           0
05/08 18:22:12   weight_scale         0.1
05/08 18:22:12 creating model
05/08 18:22:12 using device: /gpu:0
05/08 18:22:12 copying vocab to experiments/APE17/edits/noisy/forced_noisy/data/vocab.mt
05/08 18:22:12 copying vocab to experiments/APE17/edits/noisy/forced_noisy/data/vocab.edits
05/08 18:22:12 reading vocabularies
05/08 18:22:12 creating model
05/08 18:22:13 model parameters (19)
05/08 18:22:13   learning_rate:0 ()
05/08 18:22:13   global_step:0 ()
05/08 18:22:13   dropout_keep_prob:0 ()
05/08 18:22:13   embedding_mt:0 (30000, 256)
05/08 18:22:13   encoder_mt/initial_state_fw:0 (512,)
05/08 18:22:13   encoder_mt/initial_state_bw:0 (512,)
05/08 18:22:13   encoder_mt/stack_bidirectional_rnn/cell_0/bidirectional_rnn/fw/layer_norm_basic_lstm_cell/weights:0 (512, 1024)
05/08 18:22:13   encoder_mt/stack_bidirectional_rnn/cell_0/bidirectional_rnn/fw/layer_norm_basic_lstm_cell/biases:0 (1024,)
05/08 18:22:13   encoder_mt/stack_bidirectional_rnn/cell_0/bidirectional_rnn/bw/layer_norm_basic_lstm_cell/weights:0 (512, 1024)
05/08 18:22:13   encoder_mt/stack_bidirectional_rnn/cell_0/bidirectional_rnn/bw/layer_norm_basic_lstm_cell/biases:0 (1024,)
05/08 18:22:13   embedding_edits:0 (30000, 256)
05/08 18:22:13   decoder_edits/initial_state_projection/kernel:0 (256, 512)
05/08 18:22:13   decoder_edits/initial_state_projection/bias:0 (512,)
05/08 18:22:13   decoder_edits/maxout/kernel:0 (1280, 256)
05/08 18:22:13   decoder_edits/softmax0/kernel:0 (128, 256)
05/08 18:22:13   decoder_edits/softmax1/kernel:0 (256, 30000)
05/08 18:22:13   decoder_edits/softmax1/bias:0 (30000,)
05/08 18:22:13   decoder_edits/layer_norm_basic_lstm_cell/weights:0 (1024, 1024)
05/08 18:22:13   decoder_edits/layer_norm_basic_lstm_cell/biases:0 (1024,)
05/08 18:22:13 number of parameters: 25.66M
05/08 18:22:14 reading training and development data
05/08 18:22:14 reading training data
05/08 18:22:15   reading data line 100000
05/08 18:22:17   reading data line 200000
05/08 18:22:18   reading data line 300000
05/08 18:22:20   reading data line 400000
05/08 18:22:21   reading data line 500000
05/08 18:22:23   reading data line 600000
05/08 18:22:24   reading data line 700000
05/08 18:22:25 files: experiments/APE17/edits/data/train.noisy.mt experiments/APE17/edits/data/train.noisy.edits
05/08 18:22:25 size: 732070
05/08 18:22:25 reading development data
05/08 18:22:25 files: experiments/APE17/edits/data/train-dev.mt experiments/APE17/edits/data/train-dev.edits
05/08 18:22:25 size: 1000
05/08 18:22:25 starting training
05/08 18:23:30 step 400 epoch 1 learning rate 1.0000 step-time 0.1634 loss 62.9713
05/08 18:23:33   train-dev eval: loss 43.62
05/08 18:23:33 saving model to experiments/APE17/edits/noisy/forced_noisy/checkpoints
05/08 18:23:33 finished saving model
05/08 18:23:33 starting decoding
