
dropout_rate: 0.0
cell_size: 1024
attn_size: 1024
embedding_size: 512

layers: 1
bidir: True
use_lstm: False
max_output_len: 50
max_input_len: 50
weight_scale: 0.1

data_dir: experiments/APE16/trans/data_bis
model_dir: experiments/APE16/trans/xent_finetune
log_file: experiments/APE16/trans/xent_finetune/log.txt
checkpoints: [experiments/APE16/trans/xent_pretrain/checkpoints/best]
batch_size: 80

loss_function: 'xent'
optimizer: 'adadelta'

steps_per_checkpoint: 500
steps_per_eval: 500
score_function: corpus_scores_ter

max_gradient_norm: 1.0
batch_mode: 'standard'
shuffle_data: True
read_ahead: 20

train_prefix: train
max_steps: 100000
keep_best: 4
max_to_keep: 4
keep_every_n_hours: 0

encoders:
  - name: mt
#  - name: src

decoder:
    name: pe

reset: True
